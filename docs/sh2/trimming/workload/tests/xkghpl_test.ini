# Default module_template configuration.
# Lines beginning with '#' are comments; blank lines are ignored

[defaults]
work_root: ~/workload_test_suite/xkghpl_test
mode: interactive
wlm: 
job_launcher: alps
#units -  m:minutes, h:hours
wall_clock_time_limit_unit:m
wall_clock_time_limit_value:

[xkghpl_test]
test_script_source_dir:/opt/cray/cray-nvidia/default/workload/nvidia/hpl
test_script: xhpl 
test_script_parameters:
test_script_ini: 
test_script_ini_source_dir:<test_script_dir>
test_script_other_required_files: libdgemm.so.1 

#additional_cray_modules:alps,intel,gcc,craype,cudatoolkit, cray-mpich
environment_variables_template: OMP_NUM_THREADS=2;CRAY_CUDA_PROXY=1;TRSM_CUTOFF=12000;GPU_DGEMM_SPLIT=0.98;GPU_DGEMM_SPLIT2=1.00;N_SIZE=50688;TEST_LOOP=15
#test_script_other_required_files_source_dir:/opt/intel/mkl/benchmarks/mp_linpack/bin_intel/intel64
supported_accelerator_names:Tesla_K20X,Tesla_K40s,Tesla_P100-PCIE-16GB,Tesla_P100-PCIE-12GB

error_keyword_list:
error_match_exclusion_list:


[alps]
#default aprun settings 
job_launcher:aprun 
#Note: the -n option in the following command will be modified in the test script
aprun_parameters:-cc numa_node -n 4 -N 4 -L NODE_LIST -j 1 -d 2

[slurm]
job_launcher:srun 
#srun_parameters:--exclusive --gres=gpu -n WIDTH --ntasks-per-node=NPPN --nodelist=NODE_LIST --time=90
srun_parameters:--exclusive --gres=gpu -n WIDTH --ntasks-per-node=NPPN --nodelist=NODE_LIST --time=360
